---
title: "Impact of COVID-19, Economies"
author: "Jun-Yong Kim"
date: "4/1/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(countrycode)
library(dplyr)
library(rvest)
library(gt)
library(janitor)
library(infer)
library(skimr)
library(tidycensus)
library(maps)
library(sf)
library(tibble)
library(stringr)
library(readxl)
library(date)
library(gganimate)
library(chron)
```

```{r covid-19, include = FALSE}

# Downloading country-level stats on cases of COVID-19 from Worldometers

# worldometer_url <- paste0("https://www.worldometers.info/coronavirus/")
# worldometer_html <- read_html(worldometer_url)
# worldometer <- worldometer_html %>% 
#   html_nodes("table")
# worldometer <- worldometer[[1]] %>% 
#  html_table
# worldometer <- worldometer %>% 
#   clean_names() %>% 
#  rename(country_name = "country_other")

# worldometer$total_cases <- gsub(',', '', worldometer$total_cases)

#apply repeats process for rows or columns. First argument is subject (so the
#data set that we are applying to). Second argument is row or column (1 for row,
#2 for column). Last argument is the process we want repeated: get rid of the
#comma first, then get rid of the + bc (it has a special place in regular
#expression). Escape it with backspace or double backspace in gsub to remove it.
#We want to apply changes to matrix, so we have to do some work to convert to
#dataframe, numerics, etc. 

# worldometer[, -1] --> if empty, pulls everything. comes after: selects
# columns, -1 means ignore 1st column

#total cases, deaths, etc scraped

#worldometer$total_cases <- gsub(',', '', worldometer$total_cases)

# worldometer <- apply(worldometer, 2, function(x){gsub(',|\\+', '', x)})
# worldometer <- as.data.frame(worldometer)
# worldometer[, -1] <- apply(worldometer[, -1], 2, as.numeric)

#apply repeats process for rows or columns 
#first arg is subject (so data, where you wanna apply)
#second argument is row or column (1 is row, 2 is column)
#last is process that you want repeated 
#get rid of the comma first
#then get rid of the + bc it has a special place in regular expression
#escape it with backspace, or double backspace in gsub to remove it 
#apply changes to matrix, so you have to do some work to convert to dataframe, numerics, etc 
#worldometer[, -1] --> if empty, pulls everything. comes after: selects columns, -1 means ignore 1st column 

# Reading in the cleaned, prepared data from team_data

worldometer <- readRDS("../team_data/worldometer.RDS")

worldometer$country_other <- countrycode(worldometer$country_other, origin = "country.name", destination = "iso3c", warn = TRUE)

covidGlobal <- readRDS("../team_data/covidGlobal.RDS")

covidGlobal$country_region <- countrycode(covidGlobal$country_region, origin = "country.name", destination = "iso3c", warn = TRUE)

covidUS <- readRDS("../team_data/covidUS.RDS")
nytimes_states <- readRDS("../team_data/nytimes_states.RDS")
```


```{r gdp_pop_data, include = FALSE}

# Get static World Bank population data, most recent as of 2018

population_data_18 <- read_csv("API_pop.csv", skip = 3) %>% 
  clean_names() %>% 
 select(country_code, x2018) %>% 
  rename(pop_2018 = x2018)

# Get static World Bank GDP data, most recent as of 2018
  
gdp_data_18 <- read_csv("API_gdp.csv", skip = 3) %>%
  clean_names() %>% 
  select(country_code, x2018) %>% 
  rename(gdp_2018 = x2018)

# Combine and create variable for GDP per capita

gdp_pop_2018 <- gdp_data_18 %>% 
  left_join(population_data_18, by = "country_code") %>% 
  mutate(gdp_per_capita = round(gdp_2018 / pop_2018, digits = 2))

saveRDS(gdp_pop_2018, file = "gdp_per_capita.RDS")
```

```{r econ_indicators, include = FALSE}

#function to take stock indices from yahoo and scrape data every time its run (updated daily)

stock <- function(url) {
  stock_source <- paste0(url)
  stock_html <- read_html(stock_source)
  stock_data <- stock_html %>% 
  html_nodes("table")
stock_data <- stock_data[[1]] %>% 
  html_table
stock_data <- stock_data %>% 
  clean_names() %>% 
  select(date, close)
}

  
#korea

kospi <- stock("https://finance.yahoo.com/quote/%5EKS11/history?p=%5EKS11") %>% 
  rename(KOSPI = close)
kospi$date <- as.Date(kospi$date, format = "%B %d,%Y") 

#usa

nasdaq <- stock("https://finance.yahoo.com/quote/%5EIXIC/history?p=%5EIXIC") %>% 
  rename(NASDAQ = close)
nasdaq$date <- as.Date(nasdaq$date, format = "%B %d,%Y") 

#world

msci <- stock("https://finance.yahoo.com/quote/MSCI/history?p=MSCI") %>% 
  rename(MSCI = close)
msci$date <- as.Date(msci$date, format = "%B %d,%Y") 

#china

sse_china <- stock("https://finance.yahoo.com/quote/000001.SS/history?p=000001.SS") %>% 
  rename(SSE_China = close)
sse_china$date <- as.Date(sse_china$date, format = "%B %d,%Y") 

#europe as a whole 

stxe600_europe <- stock("https://finance.yahoo.com/quote/%5ESTOXX/history?p=%5ESTOXX") %>% 
  rename(STXE600_Europe = close)
stxe600_europe$date <- as.Date(stxe600_europe$date, format = "%B %d,%Y") 

#italy

ftse_italy <- stock("https://finance.yahoo.com/quote/%5EFTSE%3FP%3DFTSE/history/") %>% 
  rename(FTSE_Italy = close)
ftse_italy$date <- as.Date(ftse_italy$date, format = "%B %d,%Y") 

#spain

ibex_spain <- stock("https://finance.yahoo.com/quote/%5EIBEX/history?p=%5EIBEX") %>% 
  rename(IBEX_Spain = close)
ibex_spain$date <- as.Date(ibex_spain$date, format = "%B %d,%Y") 

#willing to add more countries here. Perhaps France / Germany ? Iran? Singapore? 

stock_data <- kospi %>% 
  left_join(nasdaq, by = "date", na.rm = TRUE) %>% 
  left_join(msci, by = "date", na.rm = TRUE) %>% 
  left_join(sse_china, by = "date", na.rm = TRUE) %>% 
  left_join(stxe600_europe, by = "date", na.rm = TRUE) %>% 
  left_join(ftse_italy, by = "date", na.rm = TRUE) %>% 
  left_join(ibex_spain, by = "date", na.rm = TRUE) 
stock_data$KOSPI <- gsub(',', '', stock_data$KOSPI) %>% as.numeric(stock_data$KOSPI)
stock_data$NASDAQ <- gsub(',', '', stock_data$NASDAQ) %>% as.numeric(stock_data$NASDAQ)
stock_data$MSCI <- gsub(',', '', stock_data$MSCI) %>% as.numeric(stock_data$MSCI)
stock_data$SSE_China <- gsub(',', '', stock_data$SSE_China) %>% as.numeric(stock_data$SSE_China)
stock_data$STXE600_Europe <- gsub(',', '', stock_data$STXE600_Europe) %>% as.numeric(stock_data$STXE600_Europe)
stock_data$FTSE_Italy <- gsub(',', '', stock_data$FTSE_Italy) %>% as.numeric(stock_data$FTSE_Italy)
stock_data$IBEX_Spain <- gsub(',', '', stock_data$IBEX_Spain) %>% as.numeric(stock_data$IBEX_Spain)

  
  
```


```{r combining, include = FALSE}


tidy_gdp_pop <- gdp_pop_2018 %>% 
 left_join(worldometer, by = c("country_code" = "country_other")) %>% 
 select(country_code, pop_2018, gdp_2018, gdp_per_capita, total_cases, total_deaths, total_recovered) %>% 
 na.omit()


```

```{r plots, echo = FALSE}

#gets today's date for downloading file

#date <- today <- format(Sys.time(), "%Y%m%d")

#crafting url by splitting up 
#citymapper_url <- "https://cdn.citymapper.com/data/cmi/Citymapper_Mobility_Index_"

#pasting together to piece it together 
#citymapper_url <- paste(citymapper_url, date, ".csv")

#downloading file from internet
#citymapper <- download.file(citymapper_url, destfile = "./citymapper.csv", quiet = TRUE)

#creating citymapper database
#citymapper <- read_csv("./citymapper.csv", skip = 3) %>% 
#  clean_names()

#citymapper <- citymapper %>% 
 # pivot_longer(-date, names_to = "city", values_to = "movement") %>%
 # left_join(msci, by = "date")
 # group_by(city) %>% 
 # nest() #%>% 
 # mutate(country = c("Netherlands", "Spain", "Germany", ))
  #do it this way annoying great

  
```

```{r visuals, echo = FALSE}

 cases_gdp_capita <- tidy_gdp_pop %>% 
 ggplot(aes(x = log(gdp_per_capita), y = log(total_cases), fill = total_deaths)) + 
 geom_point() + 
  geom_smooth(method = "lm")

#log scale accounts for outliers 

cases_gdp_capita


deaths_gdp_capita <- tidy_gdp_pop %>% 
  ggplot(aes(x = log(total_deaths), y = log(gdp_per_capita), fill = total_deaths)) + 
  geom_point() + 
  geom_smooth(method = "lm")

deaths_gdp_capita

#merged data of stock and jhu cases data 
#basically to find country vs index you take index that you want, filter countries for stock, then go 
#alternatively msci is for all countries

covid_global_stock <- covidGlobal %>% 
  left_join(stock_data, by = c("new_date" = "date")) %>% 
  rename(country = "country_region")



            
#summarized_world <- lm(MSCI ~ increment_confirmed * as.vector(country_region), data = covid_global_stock)


```


```{r}

usa <- covid_global_stock %>%
  filter(NASDAQ != "NA", country == "USA") %>%
  ggplot(aes(x = log(confirmed))) +
  transition_reveal(new_date) + 
  geom_line(aes(y = NASDAQ), na.rm = TRUE) 

usa

```
