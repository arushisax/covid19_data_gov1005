---
title: "Spread and Density of COVID-19"
author: "Rebecca Xi"
date: "4/1/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(rvest)
library(janitor)
library(infer)
library(skimr)
library(tidycensus)
library(maps)
library(sf)
library(tibble)
library(stringr)
library(readr)
library(broom)

census_api_key("5f0d2eb1b585094cfc7f8f68b50358b62af109b1")

```

```{r worldometer_scrape, include = FALSE}

# Web scraping from worldometer dataset, which aggregates total cases, total deaths,
# and total recoveries by country.

worldometer_url <- paste0("https://www.worldometers.info/coronavirus/")
worldometer_html <- read_html(worldometer_url)
worldometer <- worldometer_html %>% 
               html_nodes("table")
worldometer <- worldometer[[1]] %>% html_table
worldometer <- worldometer %>% clean_names()

# parse_number function to get the numbers
# transformations of time series, linear, and exponential

worldometer <- worldometer %>%
  mutate(total_cases = parse_number(total_cases),
         new_cases = parse_number(new_cases),
         total_deaths = parse_number(total_deaths),
         new_deaths = parse_number(new_deaths),
         total_recovered = parse_number(total_recovered),
         active_cases = parse_number(active_cases),
         serious_critical = parse_number(serious_critical),
         total_tests = parse_number(total_tests),
         tests_1m_pop = parse_number(tests_1m_pop)) %>%
  filter(! country_other %in% c("World", "Total:", "Europe", "North America", "Asia", "South America", 
                                "Africa", "Oceania", "")) %>%
  arrange(desc(total_cases))

cases_to_deaths <- lm(total_deaths ~ total_cases, data = worldometer)
cases_to_deaths %>%
  tidy(conf.int = TRUE)

ranked_worldometer <- worldometer %>%
  mutate(world_rank_cases = rank(desc(total_cases)),
         world_rank_deaths = rank(desc(total_deaths)),
         world_rank_tests = rank(desc(total_tests))) %>%
  select(country_other, total_cases, total_deaths, total_tests, world_rank_cases, world_rank_deaths,
         world_rank_tests)

ggplot(ranked_worldometer, aes(x = world_rank_tests, y = total_deaths)) + geom_point()
tests_to_deaths <- lm(total_deaths ~ total_tests, data = worldometer)
tests_to_deaths %>%
  tidy()

ggplot(ranked_worldometer, aes(x = world_rank_tests, y = total_cases)) + geom_point()
cases_to_tests <- lm(total_cases ~ total_tests, data = worldometer)
cases_to_tests %>%
  tidy()

ranked_worldometer %>%
  select(country_other, total_cases, total_deaths, world_rank_tests)

```

```{r nytimes_import, include = FALSE}

# Loading NYTimes Datasets, which have been pulled into our repository under nyt_covid_data.
# These datasets track number of cases and number of deaths by state or county by day, 
# starting with end of January until present.

nytimes_states <- read.csv(url("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"))
nytimes_counties <- read.csv(url("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"))


nytimes_counties %>%
  filter(county == "San Francisco")


```

```{r johns_hopkins, include = FALSE}
# Importing time series data from the Johns Hopkins dataset. The first three variables are timeseries datasets for
# global cases of COVID-19.

jhu_confirmed_series <- read.csv(
  "jhu_covid_data/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
  ) %>% 
  clean_names()

jhu_deaths_series <- read.csv(
  "jhu_covid_data/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
  ) %>% 
  clean_names()

jhu_recovered_series <- read.csv(
  "jhu_covid_data/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv"
  ) %>% 
  clean_names()


# These two datasets, also from Johns Hopkins, are time series datasets for the US specifically.

jhu_us_confirmed_series <- read.csv(
  "jhu_covid_data/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv"
  ) %>% 
  clean_names()

jhu_us_deaths_series <- read.csv(
  "jhu_covid_data/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"
  ) %>% 
  clean_names()

```

```{r tidy_jhu, echo = FALSE, include = FALSE}

# Pivoting the JHU data to get country, date, and confirmed cases side-by-side. Note, this dataset
# excludes results in the United States.

tidy_jhu_confirmed <- jhu_confirmed_series %>%
  pivot_longer(cols = c(x1_22_20:x4_2_20), names_to = "date", values_to = "confirmed") %>%
  select(country_region, date, confirmed) %>%
  group_by(date)

tidy_jhu_confirmed %>%
  skim()

tidy_jhu_deaths <- jhu_deaths_series %>%
  pivot_longer(cols = c(x1_22_20:x4_2_20), names_to = "date", values_to = "deaths") %>%
  select(country_region, date, deaths) %>%
  group_by(date)

tidy_jhu_deaths %>%
  skim()

tidy_jhu_recovered <- jhu_recovered_series %>%
  pivot_longer(cols = c(x1_22_20:x4_2_20), names_to = "date", values_to = "recovered") %>%
  select(country_region, date, recovered) %>%
  group_by(date)

tidy_jhu_recovered %>%
  skim()


# Pivoting the US data from JHU in a similar fashion to above.

tidy_jhu_us_confirmed <- jhu_us_confirmed_series %>%
  pivot_longer(cols = c(x1_22_20:x4_2_20), names_to = "date", values_to = "confirmed") %>%
  select(country_region, fips, combined_key, date, confirmed)

tidy_jhu_us_confirmed %>%
  group_by(combined_key, date) %>%
  arrange(desc(confirmed))

tidy_jhu_us_deaths <- jhu_us_deaths_series %>%
  pivot_longer(cols = c(x1_22_20:x4_2_20), names_to = "date", values_to = "deaths") %>%
  select(country_region, fips, combined_key, date, deaths)

tidy_jhu_us_deaths %>%
  group_by(combined_key, date) %>%
  arrange(desc(deaths))

new_jhu_deaths <- tidy_jhu_us_deaths %>%
  # filter(combined_key == "Los Angeles, California, US") %>%
  mutate(new_date = sub(".", "", date)) %>%
  mutate(new_new_date = as.Date(new_date, format = "%m_%d_%y")) %>%
  select(combined_key, new_new_date, deaths) %>%
  mutate(helper = c(new_jhu_deaths$deaths[1], new_jhu_deaths$deaths[1:(nrow(new_jhu_deaths)-1)])) %>%
  mutate(increment = deaths - helper) %>%
  group_by(combined_key)

new_set <- new_jhu_deaths %>%
  filter(increment > 0)


# Attempting to remove the x string from my JHU confirmed dataset.

# jhu_confirmed <- tidy_jhu_confirmed$date %>%
#   str_replace(pattern = "x", replacement = "")

```


```{r case_visualization, echo = FALSE}

# Function to capitalize the first letter of a string. Useful for capitalizing the
# first letter of each state pulled from the maps library, which will be joined
# on the NYTimes dataset.

CapStr <- function(y) {
  c <- strsplit(y, " ")[[1]]
  paste(toupper(substring(c, 1,1)), substring(c, 2),
      sep="", collapse=" ")
}

# Using a mix of the sf, tibble, and maps library to pull the geometry
# data by state into a table which we can join on the nytimes data.

us <- st_as_sf(map("state", plot = FALSE, fill = TRUE))
us_tbl <- as_tibble(us) %>%
  mutate(state_chr = as.character(ID)) %>%
  mutate(state = map_chr(state_chr, ~ CapStr(.))) %>%
  select(state, geom)

# Trying to join NYTimes Dataset on us_tbl data.

cases_by_state <- nytimes_states %>%
  left_join(us_tbl, by = "state") %>%
  select(date, state, cases, geom)

# Plotting a visualization of cases as of April 1st in the US.

cases_by_state %>%
  filter(date == "2020-04-01") %>%
  ggplot(aes(geometry = geom, fill = cases)) +
  geom_sf() +
  scale_fill_viridis_c(option = "plasma",
                       direction = -1) +
  labs(title = "Covid-19 Cases by State",
       subtitle = "Confirmed as of April 1st",
       caption = "Source: NYTimes",
       fill = "Confirmed Cases") +
  theme_void()

ggsave("us-covid19.png")

```

